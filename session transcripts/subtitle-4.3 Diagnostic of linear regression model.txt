We have calculated P-value of slope, confidence interval of slope and R square in the previous video using summary method of statmodels. Are they valid claims? In other words, do those assumptions which are necessary for inference hold true? In this video, we will discuss how to diagnose models and validate assumptions of models. To validate four assumptions upon a population, we only need to demonstrate that our sample data is not against these assumptions. Validation of linearity is straightforward, so a scatter plot of Y and X. In our case, scatter plot between medium price and number of rooms had linear pattern. For independence, we just need to demonstrate the observed error is independent mutually. Alternatively speaking, there is no serial correlation in errors. First, we can plot residual plot, which is the plot observed error. There's no obvious pattern in this plot. For quantitative validation of independence, we need a Durbin-Watson test. The Durbin Watson is that, there's no serial correlation in errors. In the output of summary, we can get a Durbin Watson, statistics d=0.684. To find the critical value, it is really cumbersome which depends on sample size and the number of predictors. We have a rule of thumb that test statistic values in the range of 1.5 and 2.5 are rated normal. If below 1.5, it maybe positively correlated. If above 2.5, it maybe negatively correlated, hence an assumption of independence is violated. For normality validation, we can use quantile - quantile plot or QQ plot. We use stats.probplot from python package scipy.stats to draw QQ plot. The first input of probplot is a standardized error. The second term dist = 'norm' is to compare your distribution of standardized error with normal distribution. If errors follow normal distribution, they will fall on the 45 degree line roughly. In our model, it deviates a bit in the right tail, but overall it satisfies the normality assumption. For equal variance, we can plot observed error versus predictor. If variance of noise is equal for different variance predictor, it should not have pattern. In our model, noise variance is smaller for houses with big numbers of rooms. Hence, assumption of equal variance is also violated. As we mentioned before, if assumptions are violated you cannot do a statistical inference like testing in a confidence interval. However, the model can still be applied to make a prediction. The accuracy and the consistency of your model, do not rely on these four assumptions. Let us make a conclusion. So far we've discussed simple linear regression model, and it's idea of ordinary least square estimation and the diagnostics of model assumptions. In the next two videos, we will use multiple linear regression models, to build a prediction model for price change of SPY, which is the ETF of S&P500, using multiple global index as the predictors. Finally, we will apply our model in paper trading and evaluate the performance of our models.